# ğŸ“˜ **Enriquecimento de Prompt e Query Reformulation â€” Guia Completo de Estudos**

Este documento consolida as principais tÃ©cnicas modernas de **ReformulaÃ§Ã£o de Consultas (Query Reformulation)** e **Enriquecimento de Prompts**, usadas em sistemas de RAG, agentes, mecanismos de busca e pipelines de IA.  
O objetivo Ã© ser um **material de referÃªncia** claro, didÃ¡tico e profundo para seus estudos no MBA.

---

# ğŸ§  1. O que Ã© Query Reformulation?

Query Reformulation (ou ReformulaÃ§Ã£o de Consulta) Ã© o processo de **transformar a pergunta original do usuÃ¡rio** em uma versÃ£o:

- mais clara  
- mais completa  
- mais prÃ³xima da intenÃ§Ã£o real  
- otimizada para busca ou geraÃ§Ã£o  
- mais eficaz para LLMs ou vetorizaÃ§Ã£o  

Ã‰ amplamente utilizada em:

- RAG (Retrieval-Augmented Generation)
- pipelines de busca inteligente
- agentes autÃ´nomos
- sistemas de QA (Pergunta e Resposta)
- otimizaÃ§Ã£o de prompts

---

# ğŸ§© 2. Para que serve?

- **Melhorar resultados de busca** (documentos mais relevantes)
- **Reduzir ambiguidades**
- **Aumentar a precisÃ£o de respostas**
- **Melhorar recall** (recuperar mais documentos relevantes)
- **Adaptar consultas vagas**
- **Transformar consultas curtas em consultas ricas**

---

# ğŸ›  3. Principais TÃ©cnicas de Enriquecimento e ReformulaÃ§Ã£o

Abaixo estÃ£o as tÃ©cnicas estudadas em aula, organizadas de forma clara, com:

- definiÃ§Ã£o  
- quando usar  
- quando **nÃ£o** usar  
- exemplo prÃ¡tico  

---

# ğŸ”· 3.1 Query-to-Document (Q2D)

## âœ” O que Ã©
Transforma uma consulta curta em um **pseudodocumento** mais rico, acrescentando contexto e detalhes que normalmente apareceriam em documentos reais.

A consulta vira algo muito mais parecido com o conteÃºdo que serÃ¡ buscado.

## âœ” Quando usar
- Quando a consulta do usuÃ¡rio Ã© **curta ou vaga**
- Em sistemas RAG com poucos metadados
- Para melhorar **recall**
- Em buscas semÃ¢nticas usando embeddings

## âŒ Quando NÃƒO usar
- Quando o contexto jÃ¡ estÃ¡ completo
- Quando a expansÃ£o pode criar informaÃ§Ãµes irrelevantes

## ğŸ“Œ Exemplo

**Query original:**  
> "tratamento ansiedade"

**Q2D:**  
> "Este documento descreve abordagens mÃ©dicas e terapÃªuticas para o tratamento da ansiedade, incluindo medicamentos, psicoterapia, mudanÃ§as de estilo de vida e evidÃªncias cientÃ­ficas recentes."

---

# ğŸ”· 3.2 HYDE â€” Hypothetical Document Embeddings

## âœ” O que Ã©
Uma tÃ©cnica onde o LLM gera um **documento hipotÃ©tico** que poderia responder Ã  pergunta, e este documento Ã© **vetorizado** para realizar a busca.

O foco nÃ£o Ã© o texto final, mas **os embeddings dele**.

## âœ” Quando usar
- Quando hÃ¡ poucos documentos e a busca semÃ¢ntica Ã© fraca
- Consultas muito difÃ­ceis ou tÃ©cnicas
- Perguntas onde a resposta Ã© um documento descritivo

## âŒ Quando NÃƒO usar
- Quando pode gerar um documento hipotÃ©tico incorreto demais (alucinaÃ§Ã£o irrelevante)
- Consultas numÃ©ricas diretas (nÃ£o Ã© necessÃ¡rio)

## ğŸ“Œ Exemplo

**Query:**  
> â€œComo funciona o protocolo OAuth2?â€

**HYDE Hypothetical doc:**  
> â€œO OAuth2 Ã© um protocolo baseado em tokens que permite que aplicaÃ§Ãµes acessem recursos protegidos em nome do usuÃ¡rio, utilizando fluxos como Authorization Code, Client Credentials, Resource Owner Password, entre outros...â€

Esse texto vira embedding â†’ Consulta documentos reais.

---

# ğŸ”· 3.3 Iterative Retrieval-Generation (Iter-RetGen)

## âœ” O que Ã©
Processo iterativo que combina:

1. ReformulaÃ§Ã£o da query  
2. Busca de documentos  
3. GeraÃ§Ã£o de novas queries com base nos documentos encontrados  
4. Nova busca  
5. RepetiÃ§Ã£o atÃ© convergir

Ã‰ considerado um dos mÃ©todos mais eficazes para **recuperaÃ§Ã£o profunda**.

## âœ” Quando usar
- Perguntas complexas com mÃºltiplas camadas
- Quando a primeira resposta da busca nÃ£o Ã© suficiente
- RAG avanÃ§ado com refinamento contÃ­nuo

## âŒ Quando NÃƒO usar
- Sistemas que precisam de **baixa latÃªncia**
- Consultas simples onde a primeira busca jÃ¡ resolve

## ğŸ“Œ Exemplo
UsuÃ¡rio:  
> "Como construir uma API com autorizaÃ§Ã£o em camadas?"

Pipeline:
- Query expandida: â€œmelhores prÃ¡ticas para APIs com RBAC, OAuth2 e autorizaÃ§Ã£o por rolesâ€
- Busca
- Resultado gera nova query: â€œexemplos arquiteturais de camadas de autorizaÃ§Ã£oâ€
- Busca novamente
- Soma documentos para resposta final

---

# ğŸ”· 3.4 Query Paraphrasing (Parafraseamento de Consulta)

## âœ” O que Ã©
Criar versÃµes alternativas da mesma pergunta.

Ã€s vezes outra forma da query encontra documentos diferentes.

## âœ” Quando usar
- Para aumentar **recall**
- Melhorar cobertura de busca
- Reduzir ambiguidade linguÃ­stica

## âŒ Quando NÃƒO usar
- Perguntas jÃ¡ objetivas
- Quando versÃµes alternativas mudam o sentido

## ğŸ“Œ Exemplo

Original:  
> â€œcomo melhorar produtividade em times Ã¡geisâ€

ParÃ¡frases:  
- â€œestratÃ©gias para aumentar eficiÃªncia de equipes Ã¡geisâ€  
- â€œcomo reduzir desperdÃ­cios em squads SCRUMâ€  

---

# ğŸ”· 3.5 Query Expansion (QE)

## âœ” O que Ã©
Adicionar **termos relacionados**, sinÃ´nimos e conceitos associados.

Pode ser:

- manual  
- automÃ¡tica  
- usando LLM  

## âœ” Quando usar
- Melhorar *recall* de busca longa
- Consultas vagas
- Sistemas baseados em palavras-chave

## âŒ Quando NÃƒO usar
- Quando a expansÃ£o adiciona ruÃ­do
- Quando o domÃ­nio Ã© muito tÃ©cnico e expansÃ£o pode atrapalhar

---

# ğŸ”· 3.6 Self-Ask / Decomposition

## âœ” O que Ã©
O LLM transforma a consulta original em **subperguntas menores**.

Ãštil para perguntas complexas e multi-etapas.

## âœ” Quando usar
- Perguntas de raciocÃ­nio
- RAG estruturado
- Sistemas que precisam decompor conhecimento

## âŒ Quando NÃƒO usar
- Perguntas simples
- Quando a decomposiÃ§Ã£o atrapalha a intenÃ§Ã£o

## ğŸ“Œ Exemplo

Pergunta:
> â€œComo criar um pipeline de IA com RAG e validaÃ§Ã£o de fatos?â€

DecomposiÃ§Ã£o:
1. O que Ã© RAG?  
2. Como montar um pipeline?  
3. Como validar fatos?  

---

# ğŸ”· 3.7 Query Rewriting Baseado em IntenÃ§Ã£o

## âœ” O que Ã©
Modelo identifica a **intenÃ§Ã£o real** e reescreve a pergunta para refletir isso.

## ğŸ“Œ Exemplo
UsuÃ¡rio:
> â€œPython pandas rÃ¡pidoâ€

Reescrita:
> â€œComo otimizar operaÃ§Ãµes do pandas para melhorar desempenho em grandes DataFrames?â€

---

# ğŸ”· 3.8 Multi-Step Chain Reformulation

## âœ” O que Ã©
Processo em cadeia:

1. Resolver ambiguidade  
2. Expandir  
3. Parafrasear  
4. Gerar pseudodocumento (HYDE)  
5. Rodar busca  

Ã‰ o mais avanÃ§ado, mistura mÃºltiplas tÃ©cnicas.

---

# ğŸ“ 4. Quando EU devo usar cada tÃ©cnica?

| SituaÃ§Ã£o | Melhor TÃ©cnica |
|---------|----------------|
| Query curta/difÃ­cil | HYDE, Q2D |
| Buscar documentos mais amplos | Query Expansion, Paraphrasing |
| Perguntas complexas | Iter-RetGen, Self-Ask |
| Baixa precisÃ£o | Q2D |
| Baixo recall | Parapraseamento + Expansion |
| RAG de alta qualidade | Iter-RetGen |
| DomÃ­nio muito tÃ©cnico | IntenÃ§Ã£o + Decomposition |
| Busca textual semÃ¢ntica | HYDE |

---

# ğŸ§¨ 5. Armadilhas e Riscos

- **Over-expansion** (expande demais e perde foco)
- **AlucinaÃ§Ã£o em HYDE** (texto hipotÃ©tico errado)
- **Tradeoff precisÃ£o x recall**
- **LatÃªncia alta em processos iterativos**
- **ParÃ¡frases que mudam sentido**
- **DependÃªncia excessiva do modelo**

---

# ğŸ§ª 6. Exemplos Completos

## ğŸ“Œ Exemplo completo com trÃªs tÃ©cnicas:  
UsuÃ¡rio:
> â€œMelhor forma de treinar IA para futebolâ€

Etapa 1 (Query Expansion):
> â€œtreinar modelos de IA para prever resultados de futebol, estatÃ­sticas de jogos, scouting e anÃ¡lise tÃ¡ticaâ€

Etapa 2 (HYDE):
> Documento hipotÃ©tico descrevendo datasets, modelos, mÃ©tricas e desafios

Etapa 3 (Iter-RetGen):
- Faz busca  
- Reformula com base nos docs  
- Gera nova query  
- Busca de novo  

---

# ğŸ¯ 7. ConclusÃ£o Geral

- TÃ©cnicas de enriquecimento **elevam drasticamente** a qualidade de RAG e sistemas de QA.
- Nenhuma tÃ©cnica Ã© perfeita sozinha â€” melhores resultados vÃªm de **combinaÃ§Ãµes**.
- Compreender o *quando* e o *porquÃª* aplicar cada uma Ã© mais importante do que decorÃ¡-las.

---

# ğŸ“š 8. SugestÃµes para Estudo Continuado

- Praticar implementando cada tÃ©cnica em um mini RAG
- Comparar mÃ©tricas (precisÃ£o, recall, latÃªncia)
- Estudar papers originais (ex.: HYDE: Hypothetical Document Embeddings)
- Testar pipelines com LangChain, LlamaIndex ou arquiteturas prÃ³prias

---